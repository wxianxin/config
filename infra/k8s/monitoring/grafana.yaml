apiVersion: v1
kind: PersistentVolume
metadata:
  name: monitoring-nfs-pv
  labels:
    type: monitoring-clustervault
spec:
  capacity:
    storage: 1Ti
  volumeMode: Filesystem
  storageClassName: nfs
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
    - hard
    - nfsvers=4.0
  nfs:
    path: /home/coupe/nfs_share/clustervault
    server: 192.168.8.8
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
  namespace: monitoring
spec:
  volumeMode: Filesystem
  storageClassName: nfs
  selector:                                                                             
    matchLabels:                                                                        
      type: monitoring-clustervault
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Ti # this is used when looking for PVbest way to use a single nfs share for all the deployment in a cluster with enough storage, when the clain happens, the pod always claim the entire storage capacity of the PV
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
        env:
        - name: TZ
          value: "Etc/UTC"
        volumeMounts:
          - name: nfs-storage
            mountPath: /var/lib/grafana
            subPath: grafana
        ports:
        - containerPort: 3000
      volumes:
        - name: nfs-storage
          persistentVolumeClaim:
            claimName: nfs-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  selector:
    app: grafana
  ports:
    - protocol: TCP
      targetPort: 3000
      port: 3000
      nodePort: 30003
  type: NodePort
